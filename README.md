# Проект: классификация токсичных комментариев

## Описание проекта
Интернет-магазин запускает новый сервис, позволяющий пользователям редактировать и дополнять описания товаров. Пользователи могут предлагать правки и оставлять комментарии к изменениям других клиентов.

В связи с этим возникает риск появления токсичных и оскорбительных комментариев, которые требуют дополнительной модерации.

Цель проекта — построить модель машинного обучения, которая автоматически определяет токсичность пользовательских комментариев.

Проект выполнен как исследовательская работа и ориентирован на решение задачи классификации текстовых данных с использованием методов машинного обучения и глубокого обучения.

---

## Цель и задача
**Цель:**  
Автоматически определить, является ли комментарий токсичным.

**Задача:**  
Построить модель бинарной классификации, которая по тексту комментария определяет его токсичность.

**Целевая переменная:**  
`toxic` — бинарный признак, отражающий токсичность комментария:

- 0 — комментарий не токсичный
- 1 — комментарий токсичный

---

## Данные
Данные представлены в виде CSV-файла:

- `toxic_comments.csv` — датасет с пользовательскими комментариями.

Файл содержит следующие столбцы:
- `text` — текст комментария;
- `toxic` — целевой бинарный признак.

## Использованные модели
В проекте рассмотрены следующие модели и подходы:

- логистическая регрессия с TF-IDF признаками;
- градиентный бустинг (LightGBM) с TF-IDF признаками;
- логистическая регрессия на эмбеддингах SentenceTransformers (MiniLM);
- градиентный бустинг (LightGBM) на эмбеддингах SentenceTransformers;
- fine-tuning трансформера MiniLM для задачи бинарной классификации.

Для подбора гиперпараметров использовались методы кросс-валидации.

## Метрики
Основной метрикой качества являлся F1-score, так как данные имеют выраженный дисбаланс классов.

Целью являлось получение значения метрики F1-score не ниже 0.75 на тестовой выборке.

Финальный результат лучшей модели: F1 = 0.85